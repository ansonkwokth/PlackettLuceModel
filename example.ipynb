{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjTPAg/VR9UfXrWA4QWaBc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonkwokth/PlackettLuceModel/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "YHxCfbYJ31Sn"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/ansonkwokth/PlackettLuceModel.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m unittest plackett_luce/tests/test_utils.py"
      ],
      "metadata": {
        "id": "S9oaea5HaRYV"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plackett_luce import datasets as ds\n",
        "from plackett_luce.model import PlackettLuceModel\n",
        "from plackett_luce.utils import EarlyStopper\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.manual_seed(0);\n"
      ],
      "metadata": {
        "id": "6gcfKBOE6tui"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom neural network model for flexible scoring\n",
        "class NaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(NaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Custom neural network model for flexible scoring\n",
        "class LessNaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LessNaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n"
      ],
      "metadata": {
        "id": "UB5btn3XQKOW"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_samples_train = 1000\n",
        "num_samples_test = 1000\n",
        "num_items = 14\n",
        "\n",
        "# Data generation\n",
        "print(\"Generating training and testing data...\")\n",
        "X_train, rankings_train = ds.generate_data(num_samples_train, num_items)\n",
        "X_test, rankings_test = ds.generate_data(num_samples_test, num_items)\n",
        "num_features = X_train.shape[-1]\n",
        "\n",
        "# Create item masks for variable item counts\n",
        "item_mask_train = torch.ones((num_samples_train, num_items))\n",
        "item_mask_test = torch.ones((num_samples_test, num_items))\n",
        "# Simulate some instances with fewer items (e.g., 5 items max but some with only 3)\n",
        "# item_mask_train[torch.rand(num_samples_train, num_items) < 0.2] = 0  # Randomly mask some items\n",
        "# item_mask_test[torch.rand(num_samples_test, num_items) < 0.2] = 0\n"
      ],
      "metadata": {
        "id": "3TY5mEHvRkX6",
        "outputId": "46469837-2922-4c52-eec8-495d1a87e304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training and testing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the model\n",
        "# custom_nn = NaiveNN(input_dim=num_features)\n",
        "custom_nn = LessNaiveNN(input_dim=num_features)\n",
        "# Custom early stopper\n",
        "custom_early_stopper = EarlyStopper(patience=20, min_delta=0.01)\n",
        "model = PlackettLuceModel(score_model=custom_nn, early_stopper=custom_early_stopper)\n",
        "\n",
        "# Training\n",
        "print(\"Training the model...\")\n",
        "\n",
        "model.fit(X_train, rankings_train, lr=0.01, epochs=500, top_k=3)\n",
        "# model.fit(X_train, rankings_train, lr=0.01, epochs=500)\n"
      ],
      "metadata": {
        "id": "LO-NUEov-LSI",
        "outputId": "f0573dce-c78a-4b84-878f-b056cd9c07a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Epoch 10/500, Negative Log-Likelihood: 7.3778\n",
            "Epoch 20/500, Negative Log-Likelihood: 6.6657\n",
            "Epoch 30/500, Negative Log-Likelihood: 5.6260\n",
            "Epoch 40/500, Negative Log-Likelihood: 4.5597\n",
            "Epoch 50/500, Negative Log-Likelihood: 3.6237\n",
            "Epoch 60/500, Negative Log-Likelihood: 3.2466\n",
            "Epoch 70/500, Negative Log-Likelihood: 3.0972\n",
            "Epoch 80/500, Negative Log-Likelihood: 2.9562\n",
            "Epoch 90/500, Negative Log-Likelihood: 2.8693\n",
            "Epoch 100/500, Negative Log-Likelihood: 2.7968\n",
            "Epoch 110/500, Negative Log-Likelihood: 2.7390\n",
            "Epoch 120/500, Negative Log-Likelihood: 2.6941\n",
            "Epoch 130/500, Negative Log-Likelihood: 2.6578\n",
            "Epoch 140/500, Negative Log-Likelihood: 2.6328\n",
            "Epoch 150/500, Negative Log-Likelihood: 2.6103\n",
            "Epoch 160/500, Negative Log-Likelihood: 2.5915\n",
            "Epoch 170/500, Negative Log-Likelihood: 2.5708\n",
            "Epoch 180/500, Negative Log-Likelihood: 2.5522\n",
            "Epoch 190/500, Negative Log-Likelihood: 2.5406\n",
            "Early stopping at epoch 200 with NLL 2.5301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3_aB3FSOdpl"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test the model\n",
        "print(\"\\nTesting the model...\\n\")\n",
        "predicted_rankings = model.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "top1_correct = 0\n",
        "top2_correct = 0\n",
        "top3_correct = 0\n",
        "top1in3_correct = 0\n",
        "top2in3_correct = 0\n",
        "top1or2in3_correct = 0\n",
        "\n",
        "print_first_few = 10\n",
        "for i, (pred, true) in enumerate(zip(predicted_rankings, rankings_test.tolist())):\n",
        "    if i < print_first_few:\n",
        "        print(f\"Sample {i + 1}:\")\n",
        "        print(f\"  Predicted Ranking: {pred}\")\n",
        "        print(f\"  True Ranking:      {true}\")\n",
        "\n",
        "    # Check Top-1 accuracy\n",
        "    if pred[0] == true[0]:\n",
        "        top1_correct += 1\n",
        "\n",
        "    # Check Top-2 accuracy\n",
        "    if pred[:2] == true[:2]:\n",
        "        top2_correct += 1\n",
        "\n",
        "    # Check Top-3 accuracy\n",
        "    if pred[:3] == true[:3]:\n",
        "        top3_correct += 1\n",
        "\n",
        "    # Check Top-1 in first 3 accuracy\n",
        "    if pred[0] in true[:3]:\n",
        "        top1in3_correct += 1\n",
        "    # Check Top-2 in first 3 accuracy\n",
        "    if pred[1] in true[:3]:\n",
        "        top2in3_correct += 1\n",
        "    # Check Top-1 or 2 in first 3 accuracy\n",
        "    if pred[0] in true[:3] or pred[1] in true[:3]:\n",
        "        top1or2in3_correct += 1\n",
        "\n",
        "# Compute percentages\n",
        "top1_accuracy = top1_correct / num_samples_test * 100\n",
        "top2_accuracy = top2_correct / num_samples_test * 100\n",
        "top3_accuracy = top3_correct / num_samples_test * 100\n",
        "top1in3_accuracy = top1in3_correct / num_samples_test * 100\n",
        "top2in3_accuracy = top2in3_correct / num_samples_test * 100\n",
        "top1or2in3_accuracy = top1or2in3_correct / num_samples_test * 100\n",
        "\n",
        "print(f\"\\nTop-1 or 2 in 3 Accuracy: {top1or2in3_accuracy:.2f}%\")\n",
        "print(f\"Top-1 in 3 Accuracy: {top1in3_accuracy:.2f}%\")\n",
        "print(f\"Top-2 in 3 Accuracy: {top2in3_accuracy:.2f}%\")\n",
        "print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\n",
        "print(f\"Top-2 Accuracy: {top2_accuracy:.2f}%\")\n",
        "print(f\"Top-3 Accuracy: {top3_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "p3_XLoPq_VuX",
        "outputId": "f2f95fe5-1e22-45c5-a133-97752f1f3212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the model...\n",
            "\n",
            "Sample 1:\n",
            "  Predicted Ranking: [0, 12, 2, 6, 1, 13, 9, 3, 10, 4, 7, 11, 5, 8]\n",
            "  True Ranking:      [0, 2, 12, 6, 13, 1, 9, 10, 3, 5, 4, 11, 7, 8]\n",
            "Sample 2:\n",
            "  Predicted Ranking: [13, 12, 11, 0, 6, 3, 8, 9, 2, 5, 4, 7, 1, 10]\n",
            "  True Ranking:      [13, 12, 11, 9, 6, 2, 0, 8, 3, 4, 10, 1, 7, 5]\n",
            "Sample 3:\n",
            "  Predicted Ranking: [0, 4, 6, 3, 12, 7, 8, 13, 11, 1, 10, 9, 2, 5]\n",
            "  True Ranking:      [0, 4, 6, 12, 7, 13, 3, 11, 1, 9, 8, 5, 10, 2]\n",
            "Sample 4:\n",
            "  Predicted Ranking: [8, 4, 12, 2, 0, 3, 11, 7, 5, 13, 1, 9, 6, 10]\n",
            "  True Ranking:      [8, 4, 12, 0, 13, 3, 2, 7, 11, 5, 10, 1, 6, 9]\n",
            "Sample 5:\n",
            "  Predicted Ranking: [9, 6, 0, 7, 8, 13, 4, 12, 11, 3, 1, 10, 2, 5]\n",
            "  True Ranking:      [9, 0, 7, 6, 12, 13, 11, 4, 8, 1, 5, 2, 10, 3]\n",
            "Sample 6:\n",
            "  Predicted Ranking: [10, 5, 1, 0, 9, 2, 3, 8, 13, 7, 6, 4, 11, 12]\n",
            "  True Ranking:      [5, 10, 1, 2, 9, 0, 3, 6, 7, 8, 11, 12, 4, 13]\n",
            "Sample 7:\n",
            "  Predicted Ranking: [4, 0, 2, 1, 11, 13, 3, 9, 5, 12, 7, 8, 10, 6]\n",
            "  True Ranking:      [4, 0, 1, 2, 13, 8, 3, 9, 11, 12, 5, 7, 6, 10]\n",
            "Sample 8:\n",
            "  Predicted Ranking: [7, 8, 2, 9, 13, 11, 10, 12, 6, 0, 5, 3, 1, 4]\n",
            "  True Ranking:      [2, 8, 13, 9, 7, 10, 11, 12, 6, 3, 4, 5, 1, 0]\n",
            "Sample 9:\n",
            "  Predicted Ranking: [4, 9, 7, 5, 6, 2, 8, 12, 0, 10, 1, 11, 13, 3]\n",
            "  True Ranking:      [4, 9, 7, 6, 5, 8, 0, 11, 2, 10, 13, 12, 3, 1]\n",
            "Sample 10:\n",
            "  Predicted Ranking: [10, 4, 13, 11, 7, 8, 6, 5, 9, 12, 1, 2, 3, 0]\n",
            "  True Ranking:      [10, 13, 4, 6, 11, 7, 8, 12, 2, 5, 1, 9, 0, 3]\n",
            "\n",
            "Top-1 or 2 in 3 Accuracy: 99.60%\n",
            "Top-1 in 3 Accuracy: 94.50%\n",
            "Top-2 in 3 Accuracy: 82.80%\n",
            "Top-1 Accuracy: 69.80%\n",
            "Top-2 Accuracy: 40.40%\n",
            "Top-3 Accuracy: 20.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOgq87VPkbFj"
      },
      "execution_count": 92,
      "outputs": []
    }
  ]
}