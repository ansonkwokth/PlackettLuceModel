{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlzsi35U5vPcxGHcGK1sQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonkwokth/PlackettLuceModel/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YHxCfbYJ31Sn"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/ansonkwokth/PlackettLuceModel.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m unittest plackett_luce/tests/test_utils.py"
      ],
      "metadata": {
        "id": "S9oaea5HaRYV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plackett_luce import datasets as ds\n",
        "from plackett_luce.model import PlackettLuceModel\n",
        "from plackett_luce.utils import EarlyStopper\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.manual_seed(0)\n"
      ],
      "metadata": {
        "id": "6gcfKBOE6tui"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom neural network model for flexible scoring\n",
        "class NaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(NaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Custom neural network model for flexible scoring\n",
        "class LessNaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LessNaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n"
      ],
      "metadata": {
        "id": "UB5btn3XQKOW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_samples_train = 1000\n",
        "num_samples_test = 1000\n",
        "num_items = 10\n",
        "\n",
        "# Data generation\n",
        "print(\"Generating training and testing data...\")\n",
        "X_train, rankings_train = ds.generate_data(num_samples_train, num_items)\n",
        "X_test, rankings_test = ds.generate_data(num_samples_test, num_items)\n",
        "num_features = X_train.shape[-1]\n",
        "\n",
        "# Create item masks for variable item counts\n",
        "item_mask_train = torch.ones((num_samples_train, num_items))\n",
        "item_mask_test = torch.ones((num_samples_test, num_items))\n",
        "# Simulate some instances with fewer items (e.g., 5 items max but some with only 3)\n",
        "# item_mask_train[torch.rand(num_samples_train, num_items) < 0.2] = 0  # Randomly mask some items\n",
        "# item_mask_test[torch.rand(num_samples_test, num_items) < 0.2] = 0\n"
      ],
      "metadata": {
        "id": "3TY5mEHvRkX6",
        "outputId": "8565b6ce-57e0-496b-97ef-4ebc907f6010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training and testing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the model\n",
        "# custom_nn = NaiveNN(input_dim=num_features)\n",
        "custom_nn = LessNaiveNN(input_dim=num_features)\n",
        "# Custom early stopper\n",
        "custom_early_stopper = EarlyStopper(patience=20, min_delta=0.01)\n",
        "model = PlackettLuceModel(score_model=custom_nn, early_stopper=custom_early_stopper)\n",
        "\n",
        "# Training\n",
        "print(\"Training the model...\")\n",
        "\n",
        "model.fit(X_train, rankings_train, lr=0.01, epochs=500, top_k=3)\n",
        "# model.fit(X_train, rankings_train, lr=0.01, epochs=500)\n"
      ],
      "metadata": {
        "id": "LO-NUEov-LSI",
        "outputId": "9cb3dbb3-01c5-4716-80d8-abb00915b80a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Epoch 10/500, Negative Log-Likelihood: 6.3865\n",
            "Epoch 20/500, Negative Log-Likelihood: 5.9553\n",
            "Epoch 30/500, Negative Log-Likelihood: 5.0954\n",
            "Epoch 40/500, Negative Log-Likelihood: 4.0044\n",
            "Epoch 50/500, Negative Log-Likelihood: 3.1672\n",
            "Epoch 60/500, Negative Log-Likelihood: 2.8472\n",
            "Epoch 70/500, Negative Log-Likelihood: 2.7122\n",
            "Epoch 80/500, Negative Log-Likelihood: 2.6228\n",
            "Epoch 90/500, Negative Log-Likelihood: 2.5840\n",
            "Epoch 100/500, Negative Log-Likelihood: 2.5569\n",
            "Epoch 110/500, Negative Log-Likelihood: 2.5406\n",
            "Epoch 120/500, Negative Log-Likelihood: 2.5256\n",
            "Epoch 130/500, Negative Log-Likelihood: 2.5109\n",
            "Epoch 140/500, Negative Log-Likelihood: 2.4951\n",
            "Epoch 150/500, Negative Log-Likelihood: 2.4822\n",
            "Early stopping at epoch 159 with NLL 2.4750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3_aB3FSOdpl"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test the model\n",
        "print(\"\\nTesting the model...\\n\")\n",
        "predicted_rankings = model.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "top1_correct = 0\n",
        "top2_correct = 0\n",
        "top1in3_correct = 0\n",
        "top2in3_correct = 0\n",
        "top1or2in3_correct = 0\n",
        "\n",
        "print_first_few = 10\n",
        "for i, (pred, true) in enumerate(zip(predicted_rankings, rankings_test.tolist())):\n",
        "    if i < print_first_few:\n",
        "        print(f\"Sample {i + 1}:\")\n",
        "        print(f\"  Predicted Ranking: {pred}\")\n",
        "        print(f\"  True Ranking:      {true}\")\n",
        "\n",
        "    # Check Top-1 accuracy\n",
        "    if pred[0] == true[0]:\n",
        "        top1_correct += 1\n",
        "\n",
        "    # Check Top-2 accuracy\n",
        "    if pred[:2] == true[:2]:\n",
        "        top2_correct += 1\n",
        "\n",
        "    # Check Top-1 in first 3 accuracy\n",
        "    if pred[0] in true[:3]:\n",
        "        top1in3_correct += 1\n",
        "    # Check Top-2 in first 3 accuracy\n",
        "    if pred[1] in true[:3]:\n",
        "        top2in3_correct += 1\n",
        "    # Check Top-1 or 2 in first 3 accuracy\n",
        "    if pred[0] in true[:3] or pred[1] in true[:3]:\n",
        "        top1or2in3_correct += 1\n",
        "\n",
        "# Compute percentages\n",
        "top1_accuracy = top1_correct / num_samples_test * 100\n",
        "top2_accuracy = top2_correct / num_samples_test * 100\n",
        "top1in3_accuracy = top1in3_correct / num_samples_test * 100\n",
        "top2in3_accuracy = top2in3_correct / num_samples_test * 100\n",
        "top1or2in3_accuracy = top1or2in3_correct / num_samples_test * 100\n",
        "\n",
        "print(f\"\\nTop-1 or 2 in 3 Accuracy: {top1or2in3_accuracy:.2f}%\")\n",
        "print(f\"Top-1 in 3 Accuracy: {top1in3_accuracy:.2f}%\")\n",
        "print(f\"Top-2 in 3 Accuracy: {top2in3_accuracy:.2f}%\")\n",
        "print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\n",
        "print(f\"Top-2 Accuracy: {top2_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "p3_XLoPq_VuX",
        "outputId": "45dd756f-d125-4120-9da6-954f71c2f477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the model...\n",
            "\n",
            "Sample 1:\n",
            "  Predicted Ranking: [6, 1, 0, 4, 2, 3, 5, 8, 7, 9]\n",
            "  True Ranking:      [6, 1, 0, 4, 3, 2, 5, 8, 7, 9]\n",
            "Sample 2:\n",
            "  Predicted Ranking: [8, 9, 4, 5, 6, 1, 2, 0, 7, 3]\n",
            "  True Ranking:      [8, 9, 6, 4, 5, 1, 0, 2, 7, 3]\n",
            "Sample 3:\n",
            "  Predicted Ranking: [3, 9, 6, 5, 7, 8, 4, 1, 2, 0]\n",
            "  True Ranking:      [6, 9, 8, 3, 7, 5, 1, 4, 2, 0]\n",
            "Sample 4:\n",
            "  Predicted Ranking: [6, 1, 5, 3, 0, 7, 8, 9, 2, 4]\n",
            "  True Ranking:      [7, 6, 0, 1, 5, 8, 3, 4, 9, 2]\n",
            "Sample 5:\n",
            "  Predicted Ranking: [8, 1, 4, 5, 9, 0, 6, 3, 7, 2]\n",
            "  True Ranking:      [8, 1, 5, 6, 4, 0, 9, 3, 7, 2]\n",
            "Sample 6:\n",
            "  Predicted Ranking: [0, 6, 9, 2, 7, 4, 1, 8, 5, 3]\n",
            "  True Ranking:      [2, 6, 0, 9, 1, 7, 8, 5, 3, 4]\n",
            "Sample 7:\n",
            "  Predicted Ranking: [1, 3, 7, 5, 0, 4, 9, 8, 6, 2]\n",
            "  True Ranking:      [7, 3, 0, 1, 5, 6, 8, 9, 4, 2]\n",
            "Sample 8:\n",
            "  Predicted Ranking: [9, 2, 3, 1, 8, 6, 7, 4, 5, 0]\n",
            "  True Ranking:      [2, 9, 0, 8, 3, 6, 4, 1, 7, 5]\n",
            "Sample 9:\n",
            "  Predicted Ranking: [7, 2, 0, 6, 9, 8, 3, 5, 4, 1]\n",
            "  True Ranking:      [2, 0, 7, 9, 6, 8, 5, 4, 3, 1]\n",
            "Sample 10:\n",
            "  Predicted Ranking: [7, 1, 6, 2, 3, 4, 0, 8, 5, 9]\n",
            "  True Ranking:      [7, 1, 6, 3, 8, 2, 0, 5, 4, 9]\n",
            "\n",
            "Top-1 or 2 in 3 Accuracy: 99.40%\n",
            "Top-1 in 3 Accuracy: 95.70%\n",
            "Top-2 in 3 Accuracy: 83.30%\n",
            "Top-1 Accuracy: 67.40%\n",
            "Top-2 Accuracy: 38.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOgq87VPkbFj"
      },
      "execution_count": 80,
      "outputs": []
    }
  ]
}