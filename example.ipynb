{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+DUmmeyttHyJFtO7a9Co/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonkwokth/PlackettLuceModel/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "YHxCfbYJ31Sn"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/ansonkwokth/PlackettLuceModel.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m unittest plackett_luce/tests/test_utils.py"
      ],
      "metadata": {
        "id": "S9oaea5HaRYV"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plackett_luce import datasets as ds\n",
        "from plackett_luce.model import PlackettLuceModel\n",
        "from plackett_luce.utils import EarlyStopper\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.manual_seed(0);\n"
      ],
      "metadata": {
        "id": "6gcfKBOE6tui"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom neural network model for flexible scoring\n",
        "class NaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(NaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Custom neural network model for flexible scoring\n",
        "class LessNaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LessNaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n"
      ],
      "metadata": {
        "id": "UB5btn3XQKOW"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "tkVqvrUtvMdS"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_samples_train = 5000\n",
        "num_samples_test = 1000\n",
        "num_items = 14\n",
        "\n",
        "# Data generation\n",
        "print(\"Generating training and testing data...\")\n",
        "X_train, rankings_train = ds.generate_data(num_samples_train, num_items)\n",
        "X_test, rankings_test = ds.generate_data(num_samples_test, num_items)\n",
        "num_features = X_train.shape[-1]\n",
        "\n",
        "# Create item masks for variable item counts\n",
        "item_mask_train = torch.ones((num_samples_train, num_items))\n",
        "item_mask_test = torch.ones((num_samples_test, num_items))\n",
        "# Simulate some instances with fewer items (e.g., 5 items max but some with only 3)\n",
        "# item_mask_train[torch.rand(num_samples_train, num_items) < 0.2] = 0  # Randomly mask some items\n",
        "# item_mask_test[torch.rand(num_samples_test, num_items) < 0.2] = 0\n"
      ],
      "metadata": {
        "id": "3TY5mEHvRkX6",
        "outputId": "a2a1fce3-471f-4643-953f-4b26272a06b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training and testing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the model\n",
        "# custom_nn = NaiveNN(input_dim=num_features)\n",
        "custom_nn = LessNaiveNN(input_dim=num_features)\n",
        "# Custom early stopper\n",
        "custom_early_stopper = EarlyStopper(patience=5, min_delta=0.01)\n",
        "model = PlackettLuceModel(score_model=custom_nn, early_stopper=custom_early_stopper)\n",
        "print(f\"Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "# Training\n",
        "print(\"Training the model...\")\n",
        "\n",
        "model.fit(X_train, rankings_train, lr=0.01, epochs=500, top_k=3)\n",
        "# model.fit(X_train, rankings_train, lr=0.01, epochs=500)\n"
      ],
      "metadata": {
        "id": "LO-NUEov-LSI",
        "outputId": "beaed597-501f-4a2f-a7be-48c87031fa41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 433\n",
            "Training the model...\n",
            "Epoch 10/500, Negative Log-Likelihood: 7.3852\n",
            "Epoch 20/500, Negative Log-Likelihood: 6.6363\n",
            "Epoch 30/500, Negative Log-Likelihood: 5.3059\n",
            "Epoch 40/500, Negative Log-Likelihood: 3.9189\n",
            "Epoch 50/500, Negative Log-Likelihood: 3.3756\n",
            "Epoch 60/500, Negative Log-Likelihood: 3.1504\n",
            "Epoch 70/500, Negative Log-Likelihood: 3.0107\n",
            "Epoch 80/500, Negative Log-Likelihood: 2.9025\n",
            "Epoch 90/500, Negative Log-Likelihood: 2.8223\n",
            "Epoch 100/500, Negative Log-Likelihood: 2.7609\n",
            "Epoch 110/500, Negative Log-Likelihood: 2.7024\n",
            "Early stopping at epoch 114 with NLL 2.6835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3_aB3FSOdpl"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test the model\n",
        "print(\"\\nTesting the model...\\n\")\n",
        "predicted_rankings = model.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "top1_correct = 0\n",
        "top2_correct = 0\n",
        "top3_correct = 0\n",
        "top1in3_correct = 0\n",
        "top2in3_correct = 0\n",
        "top1or2in3_correct = 0\n",
        "\n",
        "print_first_few = 10\n",
        "for i, (pred, true) in enumerate(zip(predicted_rankings, rankings_test.tolist())):\n",
        "    if i < print_first_few:\n",
        "        print(f\"Sample {i + 1}:\")\n",
        "        print(f\"  Predicted Ranking: {pred}\")\n",
        "        print(f\"  True Ranking:      {true}\")\n",
        "\n",
        "    # Check Top-1 accuracy\n",
        "    if pred[0] == true[0]:\n",
        "        top1_correct += 1\n",
        "\n",
        "    # Check Top-2 accuracy\n",
        "    if pred[:2] == true[:2]:\n",
        "        top2_correct += 1\n",
        "\n",
        "    # Check Top-3 accuracy\n",
        "    if pred[:3] == true[:3]:\n",
        "        top3_correct += 1\n",
        "\n",
        "    # Check Top-1 in first 3 accuracy\n",
        "    if pred[0] in true[:3]:\n",
        "        top1in3_correct += 1\n",
        "    # Check Top-2 in first 3 accuracy\n",
        "    if pred[1] in true[:3]:\n",
        "        top2in3_correct += 1\n",
        "    # Check Top-1 or 2 in first 3 accuracy\n",
        "    if pred[0] in true[:3] or pred[1] in true[:3]:\n",
        "        top1or2in3_correct += 1\n",
        "\n",
        "# Compute percentages\n",
        "top1_accuracy = top1_correct / num_samples_test * 100\n",
        "top2_accuracy = top2_correct / num_samples_test * 100\n",
        "top3_accuracy = top3_correct / num_samples_test * 100\n",
        "top1in3_accuracy = top1in3_correct / num_samples_test * 100\n",
        "top2in3_accuracy = top2in3_correct / num_samples_test * 100\n",
        "top1or2in3_accuracy = top1or2in3_correct / num_samples_test * 100\n",
        "\n",
        "print(f\"\\nTop-1 or 2 in 3 Accuracy: {top1or2in3_accuracy:.2f}%\")\n",
        "print(f\"Top-1 in 3 Accuracy: {top1in3_accuracy:.2f}%\")\n",
        "print(f\"Top-2 in 3 Accuracy: {top2in3_accuracy:.2f}%\")\n",
        "print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\n",
        "print(f\"Top-2 Accuracy: {top2_accuracy:.2f}%\")\n",
        "print(f\"Top-3 Accuracy: {top3_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "p3_XLoPq_VuX",
        "outputId": "8e0879eb-5c51-44bf-ec3e-1e111db71303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the model...\n",
            "\n",
            "Sample 1:\n",
            "  Predicted Ranking: [6, 8, 11, 4, 5, 7, 12, 1, 0, 13, 2, 10, 3, 9]\n",
            "  True Ranking:      [6, 11, 5, 4, 0, 12, 8, 1, 13, 7, 3, 2, 10, 9]\n",
            "Sample 2:\n",
            "  Predicted Ranking: [12, 4, 6, 5, 2, 13, 10, 0, 8, 11, 7, 3, 9, 1]\n",
            "  True Ranking:      [6, 12, 4, 2, 10, 13, 5, 3, 7, 11, 8, 9, 1, 0]\n",
            "Sample 3:\n",
            "  Predicted Ranking: [9, 10, 0, 6, 3, 1, 2, 4, 13, 7, 12, 11, 8, 5]\n",
            "  True Ranking:      [0, 9, 10, 2, 3, 13, 1, 4, 6, 12, 7, 11, 5, 8]\n",
            "Sample 4:\n",
            "  Predicted Ranking: [9, 0, 12, 3, 7, 4, 2, 6, 5, 10, 8, 1, 13, 11]\n",
            "  True Ranking:      [9, 3, 2, 12, 1, 8, 0, 4, 7, 11, 6, 10, 13, 5]\n",
            "Sample 5:\n",
            "  Predicted Ranking: [1, 5, 11, 9, 4, 12, 8, 3, 6, 7, 2, 0, 10, 13]\n",
            "  True Ranking:      [1, 5, 8, 11, 9, 3, 4, 6, 12, 7, 2, 10, 0, 13]\n",
            "Sample 6:\n",
            "  Predicted Ranking: [13, 7, 8, 9, 2, 3, 6, 11, 10, 1, 0, 4, 12, 5]\n",
            "  True Ranking:      [13, 7, 8, 9, 2, 3, 6, 1, 11, 10, 0, 4, 5, 12]\n",
            "Sample 7:\n",
            "  Predicted Ranking: [3, 9, 4, 11, 5, 10, 6, 8, 12, 7, 2, 0, 1, 13]\n",
            "  True Ranking:      [3, 9, 4, 11, 10, 5, 8, 6, 2, 7, 0, 12, 1, 13]\n",
            "Sample 8:\n",
            "  Predicted Ranking: [7, 6, 4, 11, 2, 12, 0, 9, 5, 13, 10, 8, 3, 1]\n",
            "  True Ranking:      [7, 6, 12, 0, 4, 9, 2, 11, 5, 8, 3, 1, 13, 10]\n",
            "Sample 9:\n",
            "  Predicted Ranking: [7, 8, 12, 11, 2, 4, 5, 13, 1, 6, 3, 9, 10, 0]\n",
            "  True Ranking:      [12, 8, 2, 11, 7, 5, 13, 4, 6, 10, 1, 9, 3, 0]\n",
            "Sample 10:\n",
            "  Predicted Ranking: [1, 7, 6, 11, 8, 5, 13, 12, 9, 0, 3, 4, 10, 2]\n",
            "  True Ranking:      [1, 8, 11, 5, 12, 6, 13, 7, 9, 3, 10, 0, 4, 2]\n",
            "\n",
            "Top-1 or 2 in 3 Accuracy: 99.60%\n",
            "Top-1 in 3 Accuracy: 97.00%\n",
            "Top-2 in 3 Accuracy: 86.40%\n",
            "Top-1 Accuracy: 73.30%\n",
            "Top-2 Accuracy: 45.10%\n",
            "Top-3 Accuracy: 26.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOgq87VPkbFj"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbU0PohMxq79"
      },
      "execution_count": 106,
      "outputs": []
    }
  ]
}