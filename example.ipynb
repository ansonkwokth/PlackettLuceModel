{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ3cp8ctV/L0/bD7pOjcER",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonkwokth/PlackettLuceModel/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YHxCfbYJ31Sn"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/ansonkwokth/PlackettLuceModel.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m unittest plackett_luce/tests/test_utils.py"
      ],
      "metadata": {
        "id": "S9oaea5HaRYV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plackett_luce import datasets as ds\n",
        "from plackett_luce.model import PlackettLuceModel\n",
        "from plackett_luce.utils import EarlyStopper\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.manual_seed(0);\n"
      ],
      "metadata": {
        "id": "6gcfKBOE6tui"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate fake data with fixed number of items at each instance"
      ],
      "metadata": {
        "id": "dJ4W1e6HaVMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_samples_train = 5000\n",
        "num_samples_test = 1000\n",
        "num_items = 5\n",
        "\n",
        "# Data generation\n",
        "print(\"Generating training and testing data...\")\n",
        "X_train, rankings_train = ds.generate_data(num_samples_train, num_items)\n",
        "X_test, rankings_test = ds.generate_data(num_samples_test, num_items)\n",
        "\n",
        "# Create item masks for variable item counts\n",
        "mask_train = torch.ones((num_samples_train, num_items)).int()\n",
        "mask_test = torch.ones((num_samples_test, num_items)).int()"
      ],
      "metadata": {
        "id": "3TY5mEHvRkX6",
        "outputId": "21f7ed0f-7dd9-4206-b771-9d53ece0bcdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training and testing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "4q3UJSFFblVO",
        "outputId": "98938da8-58fd-4cc4-f817-f29f739196dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5000, 5, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and train models"
      ],
      "metadata": {
        "id": "1Oiobursaf9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom neural network model for flexible scoring\n",
        "class NaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(NaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Custom neural network model for flexible scoring\n",
        "class LessNaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LessNaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n"
      ],
      "metadata": {
        "id": "UB5btn3XQKOW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X_train.shape[-1]\n",
        "\n",
        "# Initialize the model\n",
        "# custom_nn = NaiveNN(input_dim=num_features)\n",
        "custom_nn = LessNaiveNN(input_dim=num_features)\n",
        "# Custom early stopper\n",
        "custom_early_stopper = EarlyStopper(patience=5, min_delta=0.01)\n",
        "model = PlackettLuceModel(score_model=custom_nn, early_stopper=custom_early_stopper)\n",
        "print(f\"Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "# Training\n",
        "print(\"Training the model...\")\n",
        "\n",
        "model.fit(X_train, rankings_train, lr=0.01, epochs=500, top_k=3, item_mask=mask_train)\n"
      ],
      "metadata": {
        "id": "LO-NUEov-LSI",
        "outputId": "7f353b14-510d-406a-bdbf-da7fc0269eeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 433\n",
            "Training the model...\n",
            "Epoch 10/500, Negative Log-Likelihood: 3.9073\n",
            "Epoch 20/500, Negative Log-Likelihood: 3.4410\n",
            "Epoch 30/500, Negative Log-Likelihood: 2.7851\n",
            "Epoch 40/500, Negative Log-Likelihood: 2.1153\n",
            "Epoch 50/500, Negative Log-Likelihood: 1.9149\n",
            "Epoch 60/500, Negative Log-Likelihood: 1.8176\n",
            "Epoch 70/500, Negative Log-Likelihood: 1.7612\n",
            "Epoch 80/500, Negative Log-Likelihood: 1.7177\n",
            "Early stopping at epoch 86 with NLL 1.6968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3_aB3FSOdpl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate model"
      ],
      "metadata": {
        "id": "ssqknKCLbBep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, rankings_test):\n",
        "    # Test the model\n",
        "    print(\"\\nTesting the model...\\n\")\n",
        "    predicted_rankings = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the performance\n",
        "    top1_correct = 0\n",
        "    top2_correct = 0\n",
        "    top3_correct = 0\n",
        "    top1in3_correct = 0\n",
        "    top2in3_correct = 0\n",
        "    top1or2in3_correct = 0\n",
        "\n",
        "    print_first_few = 10\n",
        "    for i, (pred, true) in enumerate(zip(predicted_rankings, rankings_test.tolist())):\n",
        "        if i < print_first_few:\n",
        "            print(f\"Sample {i + 1}:\")\n",
        "            print(f\"  Predicted Ranking: {pred}\")\n",
        "            print(f\"  True Ranking:      {true}\")\n",
        "\n",
        "        # Check Top-1 accuracy\n",
        "        if pred[0] == true[0]:\n",
        "            top1_correct += 1\n",
        "\n",
        "        # Check Top-2 accuracy\n",
        "        if pred[:2] == true[:2]:\n",
        "            top2_correct += 1\n",
        "\n",
        "        # Check Top-3 accuracy\n",
        "        if pred[:3] == true[:3]:\n",
        "            top3_correct += 1\n",
        "\n",
        "        # Check Top-1 in first 3 accuracy\n",
        "        if pred[0] in true[:3]:\n",
        "            top1in3_correct += 1\n",
        "        # Check Top-2 in first 3 accuracy\n",
        "        if pred[1] in true[:3]:\n",
        "            top2in3_correct += 1\n",
        "        # Check Top-1 or 2 in first 3 accuracy\n",
        "        if pred[0] in true[:3] or pred[1] in true[:3]:\n",
        "            top1or2in3_correct += 1\n",
        "\n",
        "    # Compute percentages\n",
        "    top1_accuracy = top1_correct / X_test.shape[0] * 100\n",
        "    top2_accuracy = top2_correct / X_test.shape[0] * 100\n",
        "    top3_accuracy = top3_correct / X_test.shape[0] * 100\n",
        "    top1in3_accuracy = top1in3_correct / X_test.shape[0] * 100\n",
        "    top2in3_accuracy = top2in3_correct / X_test.shape[0] * 100\n",
        "    top1or2in3_accuracy = top1or2in3_correct / X_test.shape[0] * 100\n",
        "\n",
        "    print(f\"\\nTop-1 or 2 in 3 Accuracy: {top1or2in3_accuracy:.2f}%\")\n",
        "    print(f\"Top-1 in 3 Accuracy: {top1in3_accuracy:.2f}%\")\n",
        "    print(f\"Top-2 in 3 Accuracy: {top2in3_accuracy:.2f}%\")\n",
        "    print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\n",
        "    print(f\"Top-2 Accuracy: {top2_accuracy:.2f}%\")\n",
        "    print(f\"Top-3 Accuracy: {top3_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "p3_XLoPq_VuX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, X_test, rankings_test)"
      ],
      "metadata": {
        "id": "rOgq87VPkbFj",
        "outputId": "c8f30176-73db-48e2-8611-53cb961ba9b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the model...\n",
            "\n",
            "Sample 1:\n",
            "  Predicted Ranking: [4, 3, 1, 2, 0]\n",
            "  True Ranking:      [4, 1, 3, 2, 0]\n",
            "Sample 2:\n",
            "  Predicted Ranking: [2, 0, 3, 4, 1]\n",
            "  True Ranking:      [0, 2, 4, 3, 1]\n",
            "Sample 3:\n",
            "  Predicted Ranking: [3, 4, 1, 2, 0]\n",
            "  True Ranking:      [3, 1, 4, 2, 0]\n",
            "Sample 4:\n",
            "  Predicted Ranking: [0, 2, 4, 3, 1]\n",
            "  True Ranking:      [0, 2, 4, 3, 1]\n",
            "Sample 5:\n",
            "  Predicted Ranking: [0, 3, 4, 1, 2]\n",
            "  True Ranking:      [0, 4, 2, 1, 3]\n",
            "Sample 6:\n",
            "  Predicted Ranking: [4, 1, 0, 3, 2]\n",
            "  True Ranking:      [1, 4, 0, 3, 2]\n",
            "Sample 7:\n",
            "  Predicted Ranking: [2, 4, 1, 3, 0]\n",
            "  True Ranking:      [2, 4, 1, 0, 3]\n",
            "Sample 8:\n",
            "  Predicted Ranking: [3, 1, 4, 0, 2]\n",
            "  True Ranking:      [3, 1, 2, 4, 0]\n",
            "Sample 9:\n",
            "  Predicted Ranking: [0, 3, 4, 1, 2]\n",
            "  True Ranking:      [0, 3, 4, 1, 2]\n",
            "Sample 10:\n",
            "  Predicted Ranking: [2, 1, 0, 4, 3]\n",
            "  True Ranking:      [2, 1, 0, 4, 3]\n",
            "\n",
            "Top-1 or 2 in 3 Accuracy: 100.00%\n",
            "Top-1 in 3 Accuracy: 98.40%\n",
            "Top-2 in 3 Accuracy: 93.90%\n",
            "Top-1 Accuracy: 79.20%\n",
            "Top-2 Accuracy: 58.80%\n",
            "Top-3 Accuracy: 41.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbU0PohMxq79"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7jPK3itCUHK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2b0JwE3TCUKQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4V5rL0dQCUNp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KYnuVomkCUQu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2biWOJpNTuxg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate fake data with variable number of items at each instance"
      ],
      "metadata": {
        "id": "2z1luYTFdD8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_, rankings_train_ = ds.generate_data_varaible_items(num_samples=num_samples_train, num_items_range=(8, 14))\n",
        "X_test_, rankings_test_ = ds.generate_data_varaible_items(num_samples=num_samples_test, num_items_range=(8, 14))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pS1p--pNdHvz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_min_max_items(rankings_train):\n",
        "    min_items = min(len(rank_i) for rank_i in rankings_train)\n",
        "    max_items = max(len(rank_i) for rank_i in rankings_train)\n",
        "\n",
        "    return min_items, max_items\n",
        "\n",
        "\n",
        "def get_masked(X, rankings, max_items):\n",
        "    n_samples = len(rankings)\n",
        "    n_features = len(X[0][0]) if X and X[0] else 0  # Handle empty input gracefully\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        n_empty = max_items - len(X[i])\n",
        "        if n_empty > 0:\n",
        "            rankings[i].extend([np.nan] * n_empty)\n",
        "            X[i].extend([[np.nan] * n_features] * n_empty)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X = np.array(X, dtype=float)\n",
        "    rankings = np.array(rankings, dtype=float)\n",
        "\n",
        "    # Create mask and handle NaNs\n",
        "    mask = ~np.isnan(rankings)\n",
        "    X[np.isnan(X)] = 0\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X = torch.tensor(X, dtype=torch.float32)\n",
        "    rankings = torch.tensor(rankings, dtype=torch.int32)\n",
        "    mask = torch.tensor(mask, dtype=torch.int32)\n",
        "\n",
        "    return X, rankings, mask\n"
      ],
      "metadata": {
        "id": "CdurEldiCb4g"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_items, max_items = find_min_max_items(rankings_train_)\n",
        "\n",
        "X_train, rankings_train, mask_train = get_masked(X_train_, rankings_train_, max_items)\n",
        "X_test, rankings_test, mask_test = get_masked(X_test_, rankings_test_, max_items)\n"
      ],
      "metadata": {
        "id": "r4CFBWd0GopQ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the model\n",
        "# custom_nn = NaiveNN(input_dim=num_features)\n",
        "custom_nn = LessNaiveNN(input_dim=num_features)\n",
        "# Custom early stopper\n",
        "custom_early_stopper = EarlyStopper(patience=5, min_delta=0.01)\n",
        "model = PlackettLuceModel(score_model=custom_nn, early_stopper=custom_early_stopper)\n",
        "print(f\"Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "# Training\n",
        "print(\"Training the model...\")\n",
        "\n",
        "model.fit(X_train, rankings_train, lr=0.01, epochs=500, top_k=3, item_mask=mask_train)\n",
        "# model.fit(X_train, rankings_train, lr=0.01, epochs=500)\n"
      ],
      "metadata": {
        "id": "OyJPSBr7G6Ro",
        "outputId": "6db5dd0c-1058-46bd-c75f-ffcbf22eb212",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 433\n",
            "Training the model...\n",
            "Epoch 10/500, Negative Log-Likelihood: 7.4823\n",
            "Epoch 20/500, Negative Log-Likelihood: 6.9435\n",
            "Epoch 30/500, Negative Log-Likelihood: 5.7595\n",
            "Epoch 40/500, Negative Log-Likelihood: 4.5173\n",
            "Epoch 50/500, Negative Log-Likelihood: 4.1411\n",
            "Epoch 60/500, Negative Log-Likelihood: 3.9243\n",
            "Epoch 70/500, Negative Log-Likelihood: 3.8142\n",
            "Early stopping at epoch 79 with NLL 3.7444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, X_test, rankings_test)"
      ],
      "metadata": {
        "id": "mjdKda5rWBvU",
        "outputId": "e3a50f49-549b-491b-ce16-9b9c08679783",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the model...\n",
            "\n",
            "Sample 1:\n",
            "  Predicted Ranking: [1, 3, 0, 4, 6, 7, 2, 5, 8, 9, 10, 11, 12, 13]\n",
            "  True Ranking:      [1, 3, 0, 4, 7, 6, 5, 2, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648]\n",
            "Sample 2:\n",
            "  Predicted Ranking: [8, 7, 2, 6, 1, 10, 4, 5, 3, 0, 9, 11, 12, 13]\n",
            "  True Ranking:      [7, 8, 2, 6, 1, 10, 4, 5, 3, 9, 0, -2147483648, -2147483648, -2147483648]\n",
            "Sample 3:\n",
            "  Predicted Ranking: [6, 5, 2, 9, 3, 8, 1, 13, 11, 7, 4, 12, 10, 0]\n",
            "  True Ranking:      [5, 2, 6, 9, 13, 3, 8, 1, 11, 4, 12, 10, 7, 0]\n",
            "Sample 4:\n",
            "  Predicted Ranking: [5, 8, 0, 3, 6, 9, 1, 7, 2, 10, 11, 12, 13, 4]\n",
            "  True Ranking:      [5, 0, 8, 3, 6, 9, 7, 1, 2, 4, -2147483648, -2147483648, -2147483648, -2147483648]\n",
            "Sample 5:\n",
            "  Predicted Ranking: [2, 0, 3, 5, 7, 4, 6, 1, 8, 9, 10, 11, 12, 13]\n",
            "  True Ranking:      [2, 0, 3, 7, 5, 4, 6, 1, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648]\n",
            "Sample 6:\n",
            "  Predicted Ranking: [8, 2, 9, 7, 4, 5, 3, 6, 0, 1, 10, 11, 12, 13]\n",
            "  True Ranking:      [8, 9, 3, 2, 5, 4, 7, 6, 1, 0, -2147483648, -2147483648, -2147483648, -2147483648]\n",
            "Sample 7:\n",
            "  Predicted Ranking: [12, 10, 11, 2, 9, 6, 3, 0, 13, 5, 4, 7, 8, 1]\n",
            "  True Ranking:      [10, 12, 2, 11, 3, 9, 6, 0, 13, 4, 8, 7, 5, 1]\n",
            "Sample 8:\n",
            "  Predicted Ranking: [10, 2, 8, 9, 6, 3, 0, 5, 7, 1, 4, 11, 12, 13]\n",
            "  True Ranking:      [10, 2, 9, 3, 8, 6, 0, 1, 5, 4, 7, -2147483648, -2147483648, -2147483648]\n",
            "Sample 9:\n",
            "  Predicted Ranking: [3, 9, 12, 11, 4, 7, 6, 5, 1, 0, 10, 2, 13, 8]\n",
            "  True Ranking:      [9, 12, 3, 6, 11, 4, 5, 0, 7, 10, 1, 2, 8, -2147483648]\n",
            "Sample 10:\n",
            "  Predicted Ranking: [5, 6, 4, 0, 1, 11, 10, 2, 13, 7, 12, 8, 3, 9]\n",
            "  True Ranking:      [5, 6, 4, 0, 1, 10, 11, 2, 8, 13, 12, 7, 3, 9]\n",
            "\n",
            "Top-1 or 2 in 3 Accuracy: 98.80%\n",
            "Top-1 in 3 Accuracy: 96.10%\n",
            "Top-2 in 3 Accuracy: 83.60%\n",
            "Top-1 Accuracy: 72.40%\n",
            "Top-2 Accuracy: 44.90%\n",
            "Top-3 Accuracy: 26.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wm93TZm8ZKFU"
      },
      "execution_count": 66,
      "outputs": []
    }
  ]
}