{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9DTaxLemUcqpEylUBY5nH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonkwokth/PlackettLuceModel/blob/main/example_dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install package from github"
      ],
      "metadata": {
        "id": "wCmIXgd9M8TJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ex4d5F5oFy3q",
        "outputId": "fe596b01-2928-410e-9956-6d0bce14adee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PlackettLuceModel'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 118 (delta 51), reused 30 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (118/118), 37.13 KiB | 2.06 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "/content/PlackettLuceModel\n",
            "Processing /content/PlackettLuceModel\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.10/dist-packages (from plackett_luce==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: torch>=2.5 in /usr/local/lib/python3.10/dist-packages (from plackett_luce==0.1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.5->plackett_luce==0.1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5->plackett_luce==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.5->plackett_luce==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5->plackett_luce==0.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.5->plackett_luce==0.1.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5->plackett_luce==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.5->plackett_luce==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.5->plackett_luce==0.1.0) (3.0.2)\n",
            "Building wheels for collected packages: plackett_luce\n",
            "  Building wheel for plackett_luce (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plackett_luce: filename=plackett_luce-0.1.0-py3-none-any.whl size=2130 sha256=25db44a45df744ffe5a946acb14a6229af263b8896ddf579e3a114581258fb0a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qf7y_ym5/wheels/a8/f1/2b/b543467c5381cc96021439e6b82036714dcdc447163a28517a\n",
            "Successfully built plackett_luce\n",
            "Installing collected packages: plackett_luce\n",
            "Successfully installed plackett_luce-0.1.0\n"
          ]
        }
      ],
      "source": [
        "# # Clone the repository\n",
        "# !git clone https://github.com/ansonkwokth/PlackettLuceModel.git\n",
        "\n",
        "# # Navigate to the project directory\n",
        "# %cd /content/PlackettLuceModel\n",
        "\n",
        "# # Install dependencies\n",
        "# !pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the example data set"
      ],
      "metadata": {
        "id": "4IbGgS0hNBPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python ./scripts/generate_example_data.py"
      ],
      "metadata": {
        "id": "Mcz2_7EgF1tv",
        "outputId": "bf5f5dd2-2211-4537-b4fa-f9b6eac87ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PlackettLuceModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example usage"
      ],
      "metadata": {
        "id": "C9ik7UdpLXg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/PlackettLuceModel\n",
        "from plackett_luce.utils import DataLoader\n",
        "from plackett_luce.model import PlackettLuceModel\n",
        "from plackett_luce.utils import EarlyStopper\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.manual_seed(0);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRneQt0mGT8h",
        "outputId": "b775845e-badd-4547-decf-9f45b49cc6f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PlackettLuceModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading csv\n",
        "df = pd.read_csv(\"./data/example_data/example_data.csv\")"
      ],
      "metadata": {
        "id": "-imwsDXqGT7J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming df into model data format\n",
        "X, rankings, mask = DataLoader().transform(df)"
      ],
      "metadata": {
        "id": "uIQ1jXx7HnGQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6hPAsKhIGdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model"
      ],
      "metadata": {
        "id": "wnVFQJr1NjtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for simplicity, just pick the first 1000 to train\n",
        "n_train = 1000\n",
        "X_train = X[:n_train]\n",
        "rankings_train = rankings[:n_train]\n",
        "mask_train = mask[:n_train]"
      ],
      "metadata": {
        "id": "b6xD2oGVICFY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom neural network model for flexible scoring\n",
        "class LinearReg(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LinearReg, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "\n",
        "# Custom neural network model for flexible scoring\n",
        "class NaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(NaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "\n",
        "# Custom neural network model for flexible scoring\n",
        "class LessNaiveNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LessNaiveNN, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 1)  # 1D output for scoring\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "QTHlGVJ-IPuk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QaaS-3uJsAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "num_features = X_train.shape[-1]\n",
        "# custom_nn = LinearReg(input_dim=num_features)\n",
        "# custom_nn = NaiveNN(input_dim=num_features)\n",
        "custom_nn = LessNaiveNN(input_dim=num_features)\n",
        "\n",
        "# Custom early stopper\n",
        "custom_early_stopper = EarlyStopper(patience=5, min_delta=0.01)\n",
        "model = PlackettLuceModel(score_model=custom_nn, early_stopper=custom_early_stopper)\n",
        "print(f\"Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "# Training\n",
        "print(\"Training the model...\")\n",
        "\n",
        "model.fit(X_train, rankings_train, lr=0.01, epochs=500, top_k=3, item_mask=mask_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCoiqdX0Gkou",
        "outputId": "b8b695cc-0f8d-45b2-cc1f-f4ac6b851799"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 433\n",
            "Training the model...\n",
            "Epoch 10/500, Negative Log-Likelihood: 7.3644\n",
            "Epoch 20/500, Negative Log-Likelihood: 6.4733\n",
            "Epoch 30/500, Negative Log-Likelihood: 5.3179\n",
            "Epoch 40/500, Negative Log-Likelihood: 4.5474\n",
            "Epoch 50/500, Negative Log-Likelihood: 4.1401\n",
            "Epoch 60/500, Negative Log-Likelihood: 3.9446\n",
            "Epoch 70/500, Negative Log-Likelihood: 3.8218\n",
            "Epoch 80/500, Negative Log-Likelihood: 3.7418\n",
            "Early stopping at epoch 82 with NLL 3.7301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing model"
      ],
      "metadata": {
        "id": "Y3eDPrxkN5VL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for simplicity, just pick the last 10 to train\n",
        "n_test = -10\n",
        "X_test = X[n_test:]\n",
        "rankings_test = rankings[n_test:]\n",
        "mask_test = mask[n_test:]"
      ],
      "metadata": {
        "id": "5ODtY31KLh3V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "pred_test = model.predict(X_test)\n",
        "pred_test = torch.tensor(pred_test)\n",
        "# replace the dumpy entry by -99\n",
        "pred_test[mask_test == 0] = -99"
      ],
      "metadata": {
        "id": "BEUAuaAYKIxw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(10):\n",
        "    print(\"instance\", i+1)\n",
        "    print(\"Pred first 5\", pred_test[i][:5].tolist())\n",
        "    print(\"True first 5\", rankings_test[i][:5].tolist())\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fPEjY-WKz1G",
        "outputId": "001fd242-58ca-467b-9f62-632d895e9cc0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instance 1\n",
            "Pred first 5 [6, 7, 9, 8, 1]\n",
            "True first 5 [6, 9, 3, 7, 8]\n",
            "\n",
            "instance 2\n",
            "Pred first 5 [0, 4, 3, 1, 6]\n",
            "True first 5 [0, 4, 1, 3, 6]\n",
            "\n",
            "instance 3\n",
            "Pred first 5 [1, 4, 2, 10, 7]\n",
            "True first 5 [1, 3, 4, 0, 10]\n",
            "\n",
            "instance 4\n",
            "Pred first 5 [11, 1, 12, 0, 10]\n",
            "True first 5 [11, 12, 0, 5, 2]\n",
            "\n",
            "instance 5\n",
            "Pred first 5 [6, 5, 3, 1, 2]\n",
            "True first 5 [3, 6, 2, 5, 1]\n",
            "\n",
            "instance 6\n",
            "Pred first 5 [6, 4, 8, 9, 0]\n",
            "True first 5 [6, 8, 9, 4, 0]\n",
            "\n",
            "instance 7\n",
            "Pred first 5 [8, 13, 12, 2, 9]\n",
            "True first 5 [13, 12, 8, 9, 2]\n",
            "\n",
            "instance 8\n",
            "Pred first 5 [9, 6, 7, 2, 3]\n",
            "True first 5 [6, 2, 7, 4, 3]\n",
            "\n",
            "instance 9\n",
            "Pred first 5 [6, 8, 2, 4, 1]\n",
            "True first 5 [8, 6, 4, 0, 2]\n",
            "\n",
            "instance 10\n",
            "Pred first 5 [1, 5, 0, 8, 3]\n",
            "True first 5 [3, 1, 5, 8, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-WYwbGCqK1DV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NJ41bA0bL77k"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}